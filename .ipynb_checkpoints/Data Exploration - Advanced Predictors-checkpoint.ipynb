{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression as LogReg\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import march_madness_classes as mmc\n",
    "import march_madness_games as mmg\n",
    "import march_madness_models as mmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Confirm Baseline Model is Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in the dataset\n",
    "tournament_data = pd.read_csv(\"datasets/kaggle_data/TourneyCompactResults.csv\")\n",
    "teams = pd.read_csv(\"datasets/kaggle_data/Teams.csv\")\n",
    "seeds = pd.read_csv(\"datasets/kaggle_data/TourneySeeds.csv\")\n",
    "slots = pd.read_csv(\"datasets/kaggle_data/TourneySlots.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "games_arr = mmg.filter_into_seasons(tournament_data)\n",
    "seeds_arr = mmg.filter_into_seasons(seeds)\n",
    "slots_arr = mmg.filter_into_seasons(slots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tourney_summary = pd.read_csv(\"datasets/our_data/team_summary_data/tourney_wins_matrix\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wins_in_prev_2_year = np.zeros(tourney_summary.shape)\n",
    "wins_in_prev_2_year[0:2, :] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(2, tourney_summary.shape[0]):\n",
    "    wins_in_prev_2_year[i, :] = tourney_summary.values[i - 1, :] + tourney_summary.values[i - 2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "past_resul = pd.DataFrame(wins_in_prev_2_year, columns = tourney_summary.columns, index= tourney_summary.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "past_resul.to_csv(\"datasets/our_data/past_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "past_resul.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred, resp = mmg.generate_multiple_years_of_games(range(1987, 2001), seeds_arr, slots_arr, games_arr, [\"min_index_id\", \"max_index_id\", \"markov\", \"dominance\", \"consistency\", \"prev_resul\"], [markov_data, dominance, consistency, wins_in_prev_year_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_index, cross_index = train_test_split(pred.index, test_size = .25)\n",
    "\n",
    "train_x = pred.loc[train_index]\n",
    "train_y = resp.loc[train_index]\n",
    "cross_x = pred.loc[cross_index]\n",
    "cross_y = resp.loc[cross_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(train_x.iloc[:, 2].reshape(-1,1))\n",
    "\n",
    "model = LogReg(C = 1)\n",
    "model.fit(scaler.transform(train_x.iloc[:, 2].reshape(-1,1)), train_y.values.T[0])\n",
    "model.score(scaler.transform(cross_x.iloc[:, 2].reshape(-1,1)), cross_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(train_x.iloc[:, 2:])\n",
    "\n",
    "model = LogReg(C = 1)\n",
    "model.fit(scaler.transform(train_x.iloc[:, 2:]), train_y.values.T[0])\n",
    "model.score(scaler.transform(cross_x.iloc[:, 2:]), cross_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Generate Some New Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regular_seasons = pd.read_csv(\"datasets/kaggle_data/RegularSeasonCompactResults.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regular_data = mmg.filter_into_seasons(regular_seasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "markov_data = pd.read_csv(\"datasets/our_data/stationary\", index_col=0)\n",
    "consistency = pd.read_csv(\"datasets/our_data/consistency\", index_col=0)\n",
    "dominance = pd.read_csv(\"datasets/our_data/dominance\", index_col=0)\n",
    "past_resul = pd.read_csv(\"datasets/our_data/past_results\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Seeds to Numeric Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert seeds arr to numeric value\n",
    "seed_matrix = np.zeros((2016 - 1985 + 1, teams.shape[0]))\n",
    "\n",
    "i = 0\n",
    "for year in range(1985, 2017):\n",
    "    j = 0\n",
    "    for team in teams[\"Team_Id\"]:\n",
    "        seeds_in_year_i = seeds_arr[i]\n",
    "        team_seed_in_year_i = seeds_in_year_i.loc[seeds_in_year_i[\"Team\"] == team, \"Seed\"]\n",
    "        \n",
    "        seed = np.nan\n",
    "        if len(team_seed_in_year_i.values) != 0:\n",
    "            seed = team_seed_in_year_i.values[0][1:3]\n",
    "    \n",
    "        seed_matrix[i, j] = seed\n",
    "        \n",
    "        j = j + 1\n",
    "        \n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed_matrix_df = pd.DataFrame(data=seed_matrix, columns=past_resul.columns, index=past_resul.index)\n",
    "\n",
    "seed_matrix_df.to_csv(\"datasets/our_data/team_summary_data/seeds_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed_matrix_df = pd.read_csv(\"datasets/our_data/team_summary_data/seeds_matrix\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# weighted wins = \\sum (wins / seed)\n",
    "weighted_wins_np = np.zeros(seed_matrix_df.shape)\n",
    "\n",
    "i = 0\n",
    "# iterate years\n",
    "for year in range(1985, 2017):\n",
    "    j = 0\n",
    "    # iterate teams\n",
    "    for team in teams[\"Team_Id\"]:\n",
    "        # extract games the team won\n",
    "        wins = regular_data[i].loc[regular_data[i][\"Wteam\"] == team]\n",
    "        \n",
    "        # start with 0\n",
    "        weighted_wins = 0\n",
    "        \n",
    "        # iterate wins\n",
    "        for index, game in wins.iterrows():\n",
    "            l_team = game[\"Lteam\"]\n",
    "            l_team_seed = seed_matrix_df.loc[year, str(l_team)]\n",
    "        \n",
    "            # if the loser is in the tourney, then add to weighted wins\n",
    "            if ~np.isnan(l_team_seed):\n",
    "                # ww = 1 / (lteam seed)\n",
    "                weighted_wins = weighted_wins + 1./ l_team_seed\n",
    "                \n",
    "        # put into our array\n",
    "        weighted_wins_np[i, j] = weighted_wins\n",
    "        \n",
    "        j = j + 1\n",
    "        \n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weighted_wins = pd.DataFrame(data=weighted_wins_np, columns=seed_matrix_df.columns, index=seed_matrix_df.index)\n",
    "\n",
    "weighted_wins.to_csv(\"datasets/our_data/weighted_wins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weighted_wins = pd.read_csv(\"datasets/our_data/weighted_wins\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum (Markov * Wins in Last 30 Days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "momentum_np = np.zeros(seed_matrix_df.shape)\n",
    "\n",
    "i = 0\n",
    "# iterate years\n",
    "for year in range(1985, 2017):\n",
    "    j = 0\n",
    "    # iterate teams\n",
    "    for team in teams[\"Team_Id\"]:\n",
    "        season = regular_data[i]\n",
    "        \n",
    "        # get the last 30 days of the season\n",
    "        max_day = season[\"Daynum\"].max()\n",
    "        last_month = season[season[\"Daynum\"] >= max_day - 30]\n",
    "        \n",
    "        # wins\n",
    "        wins = last_month[last_month[\"Wteam\"] == team]\n",
    "        weighted_wins = 0.\n",
    "        \n",
    "        for index, win in wins.iterrows():\n",
    "            l_team = win[\"Lteam\"]\n",
    "            l_team_pi = markov_data.loc[year, str(l_team)]\n",
    "            \n",
    "            weighted_wins = weighted_wins + l_team_pi\n",
    "        \n",
    "        momentum_np[i, j] = weighted_wins\n",
    "        j = j + 1\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "momentum = pd.DataFrame(data=momentum_np, columns=seed_matrix_df.columns, index=seed_matrix_df.index)\n",
    "\n",
    "momentum.to_csv(\"datasets/our_data/momentum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "momentum = pd.read_csv(\"datasets/our_data/momentum\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close Win Percentage (OT Wins/ Wins By <= 1 Basket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "close_wins_np = np.zeros(seed_matrix_df.shape)\n",
    "close_games_np = np.zeros(seed_matrix_df.shape)\n",
    "close_game_win_percetage_np = np.zeros(seed_matrix_df.shape)\n",
    "\n",
    "i = 0\n",
    "# iterate years\n",
    "for year in range(1985, 2017):\n",
    "    j = 0\n",
    "    # iterate teams\n",
    "    for team in teams[\"Team_Id\"]:\n",
    "        season = regular_data[i]\n",
    "        \n",
    "        # games \n",
    "        wins = season.loc[season[\"Wteam\"] == team]\n",
    "        losses = season.loc[season[\"Lteam\"] == team]\n",
    "        \n",
    "        close_wins = 0.\n",
    "        close_losses = 0.\n",
    "        \n",
    "        # iter wins, count close wins\n",
    "        for index, win in wins.iterrows():\n",
    "            if win[\"Wscore\"] - win[\"Lscore\"] <= 3:\n",
    "                close_wins = close_wins + 1.\n",
    "            elif win[\"Numot\"] > 0:\n",
    "                close_wins = close_wins + 1.\n",
    "        \n",
    "        for index, loss in losses.iterrows():\n",
    "            if loss[\"Wscore\"] - loss[\"Lscore\"] <= 3:\n",
    "                close_losses = close_losses + 1.\n",
    "            elif loss[\"Numot\"] > 0:\n",
    "                close_losses = close_losses + 1.\n",
    "        \n",
    "        close_wins_np[i, j] = close_wins\n",
    "        close_games_np[i, j] = close_wins + close_losses\n",
    "        \n",
    "        if close_wins > 0:\n",
    "            close_game_win_percetage_np[i,j] = close_wins / (close_wins +  close_losses)\n",
    "             \n",
    "        j = j + 1\n",
    "    print year\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save to database\n",
    "close_games = pd.DataFrame(data=close_games_np, columns=seed_matrix_df.columns, index=seed_matrix_df.index)\n",
    "close_games.to_csv(\"datasets/our_data/close_games\")\n",
    "\n",
    "close_wins = pd.DataFrame(data=close_wins_np, columns=seed_matrix_df.columns, index=seed_matrix_df.index)\n",
    "close_wins.to_csv(\"datasets/our_data/close_wins\")\n",
    "\n",
    "close_wins_perc = pd.DataFrame(data=close_game_win_percetage_np, columns=seed_matrix_df.columns, index=seed_matrix_df.index)\n",
    "close_wins_perc.to_csv(\"datasets/our_data/close_wins_perc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "close_games= pd.read_csv(\"datasets/our_data/close_games\", index_col=0)\n",
    "close_wins = pd.read_csv(\"datasets/our_data/close_wins\",index_col=0)\n",
    "close_wins_perc = pd.read_csv(\"datasets/our_data/close_wins_perc\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tempo (Possessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regular_seasons_detailed = pd.read_csv(\"datasets/kaggle_data/RegularSeasonDetailedResults.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Season', u'Daynum', u'Wteam', u'Wscore', u'Lteam', u'Lscore', u'Wloc',\n",
       "       u'Numot', u'Wfgm', u'Wfga', u'Wfgm3', u'Wfga3', u'Wftm', u'Wfta',\n",
       "       u'Wor', u'Wdr', u'Wast', u'Wto', u'Wstl', u'Wblk', u'Wpf', u'Lfgm',\n",
       "       u'Lfga', u'Lfgm3', u'Lfga3', u'Lftm', u'Lfta', u'Lor', u'Ldr', u'Last',\n",
       "       u'Lto', u'Lstl', u'Lblk', u'Lpf'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regular_seasons_detailed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regular_detailed = mmg.filter_into_seasons(regular_seasons_detailed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n"
     ]
    }
   ],
   "source": [
    "tempo_np = np.zeros(seed_matrix_df.shape)\n",
    "tempo_opp_np = np.zeros(seed_matrix_df.shape)\n",
    "\n",
    "i = 0\n",
    "# iterate years\n",
    "for year in range(1985, 2017):\n",
    "    j = 0\n",
    "    \n",
    "    if year < 2003:\n",
    "        tempo_np[i, :] = np.nan\n",
    "        tempo_opp_np[i,:] =np.nan\n",
    "    else:\n",
    "        # iterate teams\n",
    "        for team in teams[\"Team_Id\"]:\n",
    "            season = regular_detailed[i - (2003 - 1985)]\n",
    "\n",
    "            # games \n",
    "            wins = season.loc[season[\"Wteam\"] == team]\n",
    "            losses = season.loc[season[\"Lteam\"] == team]\n",
    "\n",
    "            possessions = 0.\n",
    "            possessions_opp = 0.\n",
    "            \n",
    "            # iterate wins\n",
    "            for index, win in wins.iterrows():\n",
    "                # possessions ~ field goal attempts - offensive rebounds + turnovers + .475 * free throw attempts\n",
    "                possessions = possessions + win['Wfga'] - win['Wor'] + win['Wto'] + .475 * win['Wfta']\n",
    "                possessions_opp = possessions_opp + win['Lfga'] - win['Lor'] + win['Lto'] + .475 * win['Lfta']\n",
    "                \n",
    "            # iterate losses\n",
    "            for index, loss in losses.iterrows():\n",
    "                # possessions ~ field goal attempts - offensive rebounds + turnovers + .475 * free throw attempts\n",
    "                possessions = possessions + loss['Lfga'] - loss['Lor'] + loss['Lto'] + .475 * loss['Lfta']\n",
    "                possessions_opp = possessions_opp + loss['Wfga'] - loss['Wor'] + loss['Wto'] + .475 * loss['Wfta']\n",
    "                \n",
    "            # update the buffer\n",
    "            if possessions == 0.:\n",
    "                tempo_np[i,j] = np.nan\n",
    "                tempo_opp_np[i,j] = np.nan\n",
    "            else:\n",
    "                tempo_np[i, j] = possessions\n",
    "                tempo_opp_np[i,j] = possessions_opp\n",
    "            \n",
    "            j = j + 1\n",
    "    i = i + 1\n",
    "    print year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tempo = pd.DataFrame(data=tempo_np, columns=seed_matrix_df.columns, index=seed_matrix_df.index)\n",
    "tempo.to_csv(\"datasets/our_data/tempo\")\n",
    "\n",
    "tempo_opp = pd.DataFrame(data=tempo_opp_np, columns=seed_matrix_df.columns, index=seed_matrix_df.index)\n",
    "tempo_opp.to_csv(\"datasets/our_data/tempo_opp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tempo = pd.read_csv(\"datasets/our_data/tempo\", index_col=0)\n",
    "tempo_opp = pd.read_csv(\"datasets/our_data/tempo_opp\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Points For/Points Against/Win Ratio/Luck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n"
     ]
    }
   ],
   "source": [
    "points_for_np = np.zeros(seed_matrix_df.shape)\n",
    "points_against_np = np.zeros(seed_matrix_df.shape)\n",
    "i = 0\n",
    "# iterate years\n",
    "for year in range(1985, 2017):\n",
    "    j = 0\n",
    "    \n",
    "    # iterate teams\n",
    "    for team in teams[\"Team_Id\"]:\n",
    "        season = regular_data[i]\n",
    "\n",
    "        # games \n",
    "        wins = season.loc[season[\"Wteam\"] == team]\n",
    "        losses = season.loc[season[\"Lteam\"] == team]\n",
    "\n",
    "        points_for = 0.\n",
    "        points_against = 0.\n",
    "\n",
    "        # iterate wins\n",
    "        for index, win in wins.iterrows():\n",
    "            # sum points\n",
    "            points_for = points_for + win[\"Wscore\"]\n",
    "            points_against = points_against + win[\"Lscore\"]\n",
    "\n",
    "        # iterate losses\n",
    "        for index, loss in losses.iterrows():\n",
    "            # sum points\n",
    "            points_for = points_for + loss[\"Lscore\"]\n",
    "            points_against = points_against + loss[\"Wscore\"]\n",
    "\n",
    "        # update the buffer\n",
    "        if points_for == 0.:\n",
    "            points_for_np[i,j] = np.nan\n",
    "            points_against_np[i,j] = np.nan\n",
    "        else:\n",
    "            points_for_np[i,j] = points_for\n",
    "            points_against_np[i,j] = points_against\n",
    "\n",
    "        j = j + 1\n",
    "    i = i + 1\n",
    "    print year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "points_for = pd.DataFrame(data=points_for_np, columns=seed_matrix_df.columns, index=seed_matrix_df.index)\n",
    "points_for.to_csv(\"datasets/our_data/points_for\")\n",
    "\n",
    "points_against = pd.DataFrame(data=points_against_np, columns=seed_matrix_df.columns, index=seed_matrix_df.index)\n",
    "points_against.to_csv(\"datasets/our_data/points_against\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pythagorean Expectation\n",
    "win_ratio_np = (points_for_np ** 11.5) / (points_for_np ** 11.5 + points_against_np ** 11.5)\n",
    "\n",
    "win_ratio = pd.DataFrame(data=win_ratio_np, columns=seed_matrix_df.columns, index=seed_matrix_df.index)\n",
    "win_ratio.to_csv(\"datasets/our_data/win_ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "points_for = pd.read_csv(\"datasets/our_data/points_for\", index_col=0)\n",
    "points_against = pd.read_csv(\"datasets/our_data/points_against\", index_col=0)\n",
    "win_ratio = pd.read_csv(\"datasets/our_data/win_ratio\", index_col=0)\n",
    "games = pd.read_csv(\"datasets/our_data/team_summary_data/games_matrix\", index_col=0)\n",
    "wins = pd.read_csv(\"datasets/our_data/team_summary_data/regular_season_wins\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# wins - expected wins\n",
    "luck = wins - win_ratio * games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offensive and Defensive Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ppp = total points for / total possessions\n",
    "points_per_possesion_np = points_for_np / tempo_np\n",
    "points_per_possesion_opp_np = points_against_np / tempo_opp_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "off_eff = pd.DataFrame(data=points_per_possesion_np, columns=seed_matrix_df.columns, index=seed_matrix_df.index)\n",
    "off_eff.to_csv(\"datasets/our_data/off_eff\")\n",
    "\n",
    "def_eff = pd.DataFrame(data=points_per_possesion_opp_np, columns=seed_matrix_df.columns, index=seed_matrix_df.index)\n",
    "def_eff.to_csv(\"datasets/our_data/def_eff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "off_eff = pd.read_csv(\"datasets/our_data/off_eff\", index_col=0)\n",
    "def_eff = pd.read_csv(\"datasets/our_data/def_eff\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adj Offensive And Defensive Efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use an itertive process to find this.\n",
    "\n",
    "Adj Off Eff = Mean Def Eff + Deviation\n",
    "\n",
    "Adj Def Eff = Mean Off Eff + Deviation\n",
    "\n",
    "Deviation = Sum_i = actual_ppp - opponent_def_ppp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_off_eff_start = off_eff.mean(axis =1).values\n",
    "mean_def_eff_start = def_eff.mean(axis =1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n"
     ]
    }
   ],
   "source": [
    "# sums of the deviations\n",
    "dev_off_np = np.zeros(seed_matrix_df.shape)\n",
    "dev_def_np = np.zeros(seed_matrix_df.shape)\n",
    "\n",
    "i = 0\n",
    "# iterate years\n",
    "for year in range(1985, 2017):\n",
    "    if year < 2003:\n",
    "        dev_off_np[i, :] = np.nan\n",
    "        dev_def_np[i,:] =np.nan\n",
    "        i = i + 1\n",
    "    else:        \n",
    "        j = 0\n",
    "        # iterate teams\n",
    "        for team in teams[\"Team_Id\"]:\n",
    "            season = regular_detailed[i - (2003 - 1985)]\n",
    "\n",
    "            # games \n",
    "            wins = season.loc[season[\"Wteam\"] == team]\n",
    "            losses = season.loc[season[\"Lteam\"] == team]\n",
    "\n",
    "            deviation_off = 0.\n",
    "            deviation_def = 0.    \n",
    "\n",
    "            # iterate wins\n",
    "            for index, win in wins.iterrows():\n",
    "                # get other team if\n",
    "                other_team = str(win[\"Lteam\"])\n",
    "\n",
    "                # points for and againsts\n",
    "                points_for = win[\"Wscore\"]\n",
    "                points_against = win[\"Lscore\"]\n",
    "\n",
    "                # possessions\n",
    "                possessions = win['Wfga'] - win['Wor'] + win['Wto'] + .475 * win['Wfta']\n",
    "                possessions_op = win['Lfga'] - win['Lor'] + win['Lto'] + .475 * win['Lfta']\n",
    "\n",
    "                # points per possession\n",
    "                ppp = points_for / possessions\n",
    "                ppp_op = points_for / possessions\n",
    "\n",
    "                # dev_i = actual ppp - opponent_def_eff\n",
    "                deviation_off = deviation_off + ppp - def_eff.loc[year, other_team]\n",
    "\n",
    "                # dev_i = actual ppp - opponent_off_eff\n",
    "                deviation_def = deviation_def + ppp_op - off_eff.loc[year, other_team]\n",
    "\n",
    "            # iterate losses\n",
    "            for index, loss in losses.iterrows():\n",
    "                # get other team if\n",
    "                other_team = str(loss[\"Wteam\"])\n",
    "\n",
    "                # points for and againsts\n",
    "                points_for = loss[\"Lscore\"]\n",
    "                points_against = loss[\"Wscore\"]\n",
    "\n",
    "                # possessions\n",
    "                possessions = loss['Lfga'] - loss['Lor'] + loss['Lto'] + .475 * loss['Lfta']\n",
    "                possessions_op = loss['Wfga'] - loss['Wor'] + loss['Wto'] + .475 * loss['Wfta']\n",
    "\n",
    "                # points per possession\n",
    "                ppp = points_for / possessions\n",
    "                ppp_op = points_for / possessions\n",
    "\n",
    "                # dev_i = actual ppp - opponent_def_eff\n",
    "                deviation_off = deviation_off + ppp - def_eff.loc[year, other_team]\n",
    "\n",
    "                # dev_i = actual ppp - opponent_off_eff\n",
    "                deviation_def = deviation_def + ppp_op - off_eff.loc[year, other_team]\n",
    "\n",
    "            # update the buffer\n",
    "            if wins.shape[0] + losses.shape[0] == 0:\n",
    "                dev_off_np[i,j] = np.nan\n",
    "                dev_def_np[i,j] = np.nan\n",
    "            else:\n",
    "                dev_off_np[i,j] = deviation_off\n",
    "                dev_off_np[i,j] = deviation_def\n",
    "\n",
    "            j = j + 1\n",
    "        i = i + 1\n",
    "        print year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        nan,         nan,         nan, ...,         nan,\n",
       "                nan,         nan],\n",
       "       [        nan,         nan,         nan, ...,         nan,\n",
       "                nan,         nan],\n",
       "       [        nan,         nan,         nan, ...,         nan,\n",
       "                nan,         nan],\n",
       "       ..., \n",
       "       [-2.36625348, -1.82235537,  0.05247388, ...,  0.72738317,\n",
       "        -0.77056818,  1.09995148],\n",
       "       [-2.31914329,  1.75394989,  0.48256294, ...,  1.58026111,\n",
       "         0.88063988,  0.30908171],\n",
       "       [-0.46906026, -1.84807523,  2.12161277, ...,  2.49936939,\n",
       "         1.86422628, -1.10592767]])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_off_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adj_off_eff = np.zeros(dev_off_np.shape)\n",
    "for i in range(dev_off_np.shape[0]):\n",
    "    adj_off_eff[i, :] = dev_off_np[i, :] + mean_def_eff_start[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        nan,         nan,         nan, ...,         nan,\n",
       "                nan,         nan],\n",
       "       [        nan,         nan,         nan, ...,         nan,\n",
       "                nan,         nan],\n",
       "       [        nan,         nan,         nan, ...,         nan,\n",
       "                nan,         nan],\n",
       "       ..., \n",
       "       [-1.32023344, -0.77633533,  1.09849391, ...,  1.7734032 ,\n",
       "         0.27545186,  2.14597152],\n",
       "       [-1.29807308,  2.77502011,  1.50363315, ...,  2.60133132,\n",
       "         1.9017101 ,  1.33015193],\n",
       "       [ 0.56847797, -0.81053701,  3.159151  , ...,  3.53690762,\n",
       "         2.90176451, -0.06838945]])"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_off_eff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([        nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "               nan,         nan,         nan,  1.0110884 ,  1.00592829,\n",
       "        1.00843796,  1.0120837 ,  1.01682775,  1.0153275 ,  1.01090295,\n",
       "        1.01314026,  1.01711846,  1.01198424,  1.006411  ,  1.04602004,\n",
       "        1.02107021,  1.03753823])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_def_eff_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Predictors from Original Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rpi = pd.read_csv(\"datasets/our_data/rpi\", index_col=0)\n",
    "bad_losses = pd.read_csv(\"datasets/our_data/bad_losses\", index_col=0)\n",
    "tough_wins = pd.read_csv(\"datasets/our_data/tough_wins\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Head to Head Wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred, resp = mmg.generate_multiple_years_of_games(range(2003, 2016), \n",
    "                                                  seeds_arr, \n",
    "                                                  slots_arr, \n",
    "                                                  games_arr, \n",
    "                                                  [\"min_index_id\", \"max_index_id\", \"markov\", \"dominance\", \"rpi\", \"bad_losses\", \"tough_wins\", \"close_wins\", \"close_wins_perc\", \"weighted_wins\", \"past_resul\", \"momentum\", \"tempo\", \"off_eff\", \"def_eff\", \"luck\"], \n",
    "                                                  [markov_data, dominance, rpi, bad_losses, tough_wins, close_wins, close_wins_perc, weighted_wins, past_resul, momentum, tempo, off_eff, def_eff, luck],\n",
    "                                                  scoring_dif = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.715609756098\n",
      "\n",
      "markov : 0.515462716526\n",
      "\n",
      "rpi : 0.888394750474\n",
      "\n",
      "bad_losses : -0.143162572217\n",
      "\n",
      "off_eff : 0.18436225876\n",
      "\n",
      "def_eff : -0.124765007925\n",
      "\n",
      "luck : -0.250712783599\n"
     ]
    }
   ],
   "source": [
    "score = 0.\n",
    "subset = [2,4,5,13,14,15]\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    train_index, cross_index = train_test_split(pred.index, test_size = .25)\n",
    "\n",
    "    train_x = pred.loc[train_index]\n",
    "    train_y = resp.loc[train_index]\n",
    "    cross_x = pred.loc[cross_index]\n",
    "    cross_y = resp.loc[cross_index]\n",
    "\n",
    "    scaler = StandardScaler().fit(train_x.iloc[:, subset])\n",
    "\n",
    "    model = LogReg(C = 1)\n",
    "    model.fit(scaler.transform(train_x.iloc[:, subset]), train_y.values.T[0])\n",
    "    score = score +  model.score(scaler.transform(cross_x.iloc[:, subset]), cross_y)\n",
    "    \n",
    "print score / 100.\n",
    "\n",
    "\n",
    "for i in range(len(pred.columns[subset].values)):\n",
    "    print \"\\n{} : {}\".format(pred.columns[subset].values[i], model.coef_[0, i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Score Differential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression as ols\n",
    "from sklearn.linear_model import Lasso as lasso\n",
    "from sklearn.linear_model import Ridge as ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred, resp = mmg.generate_multiple_years_of_games(range(1987, 2001), \n",
    "                                                  seeds_arr, \n",
    "                                                  slots_arr, \n",
    "                                                  games_arr, \n",
    "                                                  [\"min_index_id\", \"max_index_id\", \"markov\", \"dominance\", \"rpi\", \"bad_losses\", \"tough_wins\", \"close_wins\", \"close_wins_perc\", \"weighted_wins\", \"past_resul\", \"momentum\", \"win_ratio\"], \n",
    "                                                  [markov_data, dominance, rpi, bad_losses, tough_wins, close_wins, close_wins_perc, weighted_wins, past_resul, momentum, win_ratio],\n",
    "                                                  scoring_dif = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.454621409751\n",
      "[  5.26574426e+00  -2.81475572e-01   6.77657015e+00  -1.52682092e-03\n",
      "   1.00357205e+00   2.42975781e-01  -1.25747888e+00  -1.18497733e+00\n",
      "  -3.62427489e-01  -6.12538062e-01]\n"
     ]
    }
   ],
   "source": [
    "scores = 0\n",
    "for i in range(500):\n",
    "    train_index, cross_index = train_test_split(pred.index, test_size = .25)\n",
    "\n",
    "    train_x = pred.loc[train_index]\n",
    "    train_y = resp.loc[train_index]\n",
    "    cross_x = pred.loc[cross_index]\n",
    "    cross_y = resp.loc[cross_index]\n",
    "\n",
    "    scaler = StandardScaler().fit(train_x.iloc[:, 2:])\n",
    "\n",
    "    model = ols()\n",
    "    model.fit(scaler.transform(train_x.iloc[:, 2:]), train_y.values.T[0])\n",
    "    scores = scores + model.score(scaler.transform(cross_x.iloc[:, 2:]), cross_y)\n",
    "    \n",
    "print scores/500.\n",
    "print model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.455894317282\n",
      "[ 4.87620608  0.          4.47165101 -0.49475219  0.         -0.         -0.1686631\n",
      "  0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "scores = 0\n",
    "for i in range(500):\n",
    "    train_index, cross_index = train_test_split(pred.index, test_size = .25)\n",
    "\n",
    "    train_x = pred.loc[train_index]\n",
    "    train_y = resp.loc[train_index]\n",
    "    cross_x = pred.loc[cross_index]\n",
    "    cross_y = resp.loc[cross_index]\n",
    "\n",
    "    scaler = StandardScaler().fit(train_x.iloc[:, 2:])\n",
    "\n",
    "    model = lasso()\n",
    "    model.fit(scaler.transform(train_x.iloc[:, 2:]), train_y.values.T[0])\n",
    "    scores = scores + model.score(scaler.transform(cross_x.iloc[:, 2:]), cross_y)\n",
    "    \n",
    "print scores/500.\n",
    "print model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.458373670232\n",
      "[ 5.22297271  0.24896519  6.3009136  -0.42831358  0.36642889  0.4813125\n",
      " -1.37434403 -0.24265882 -0.27576285 -1.04558994]\n"
     ]
    }
   ],
   "source": [
    "scores = 0\n",
    "for i in range(500):\n",
    "    train_index, cross_index = train_test_split(pred.index, test_size = .25)\n",
    "\n",
    "    train_x = pred.loc[train_index]\n",
    "    train_y = resp.loc[train_index]\n",
    "    cross_x = pred.loc[cross_index]\n",
    "    cross_y = resp.loc[cross_index]\n",
    "\n",
    "    scaler = StandardScaler().fit(train_x.iloc[:, 2:])\n",
    "\n",
    "    model = ridge()\n",
    "    model.fit(scaler.transform(train_x.iloc[:, 2:]), train_y.values.T[0])\n",
    "    scores = scores + model.score(scaler.transform(cross_x.iloc[:, 2:]), cross_y)\n",
    "    \n",
    "print scores/500.\n",
    "print model.coef_"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
